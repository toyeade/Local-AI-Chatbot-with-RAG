{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d628d0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.13/site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in ./.venv/lib/python3.13/site-packages (from langchain-community) (0.3.75)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in ./.venv/lib/python3.13/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.13/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in ./.venv/lib/python3.13/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.13/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in ./.venv/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.13/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./.venv/lib/python3.13/site-packages (from langchain-community) (0.4.23)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./.venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./.venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.13/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "âœ… Imports successful!\n",
      "Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 1 documents\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/7rb54f0953bfshpgnhk88_sh0000gn/T/ipykernel_24341/342779084.py:23: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_model = OllamaEmbeddings(model='llama3.2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings created and stored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/7rb54f0953bfshpgnhk88_sh0000gn/T/ipykernel_24341/342779084.py:25: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install langchain-community\n",
    "#First cell - imports\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "from pydantic import Field\n",
    "import gradio as gr\n",
    "import openai\n",
    "\n",
    "print(\"âœ… Imports successful!\")\n",
    "\n",
    "# Second cell - load documents\n",
    "print(\"Loading documents...\")\n",
    "loader = DirectoryLoader('data', glob='**/*.txt')\n",
    "documents = loader.load()\n",
    "print(f\"âœ… Loaded {len(documents)} documents\")\n",
    "\n",
    "# Third cell - create embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "embedding_model = OllamaEmbeddings(model='llama3.2')\n",
    "vectordb = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"./chroma_db\")\n",
    "vectordb.persist()\n",
    "print(\"âœ… Embeddings created and stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1549eb-5863-49b4-9994-25dc97182b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load documents from the \"data\" directory\n",
    "# Load documents from the \"data\" directory (TXT and PDF files)\n",
    "print(\"Loading documents...\")\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "# Load text files\n",
    "txt_loader = DirectoryLoader('data', glob='**/*.txt')\n",
    "txt_documents = txt_loader.load()\n",
    "\n",
    "# Load PDF files\n",
    "pdf_loader = DirectoryLoader('data', glob='**/*.pdf', loader_cls=PyPDFLoader)\n",
    "pdf_documents = pdf_loader.load()\n",
    "\n",
    "# Combine all documents\n",
    "documents = txt_documents + pdf_documents\n",
    "print(f\"âœ… Loaded {len(txt_documents)} text files and {len(pdf_documents)} PDF files\")\n",
    "print(f\"âœ… Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58016342-1b4c-41c2-9318-769708228553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Create embeddings and store them in ChromaDB\n",
    "print(\"Generating embeddings...\")\n",
    "embedding_model = OllamaEmbeddings(model='llama3.2')\n",
    "vectordb = Chroma.from_documents(documents, embedding=embedding_model, persist_directory=\"./chroma_db\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48128643-3de3-4ee1-84a1-cf5611139e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Define custom LLM wrapper for llama3.2 using completion endpoint\n",
    "class SimpleOllamaLLM(LLM):\n",
    "    model: str = Field(default=\"llama3.2\", description=\"Model name to use.\")\n",
    "    base_url: str = Field(default=\"http://localhost:11434/v1\", description=\"Base URL for Ollama API.\")\n",
    "    api_key: str = Field(default=\"ollama\", description=\"Dummy API key for compatibility.\")\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None, run_manager=None) -> str:\n",
    "        client = openai.OpenAI(base_url=self.base_url, api_key=self.api_key)\n",
    "        response = client.completions.create(\n",
    "            model=self.model,\n",
    "            prompt=prompt,\n",
    "            stop=stop,\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"simple_ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c4a627-b1cd-40f5-b6da-a4835a938556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Initialize LLM and QA pipeline\n",
    "llm = SimpleOllamaLLM(model=\"llama3.2\")\n",
    "retriever = vectordb.as_retriever()\n",
    "qa_pipeline = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b47f88-35c7-49e7-ae5f-a50f632283ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/7rb54f0953bfshpgnhk88_sh0000gn/T/ipykernel_24341/1899305341.py:37: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_ui = gr.Chatbot(label=\"ðŸ’¬ Chat History\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/03/7rb54f0953bfshpgnhk88_sh0000gn/T/ipykernel_24341/1899305341.py:45: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  bot_reply = qa_pipeline.run(user_input)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define chatbot logic with toggle\n",
    "def chatbot(query, use_personal_data):\n",
    "    if use_personal_data:\n",
    "        return qa_pipeline.run(query)\n",
    "    else:\n",
    "        return llm._call(query)\n",
    "\n",
    "# Embed logo (you can also use your local image path or base64 string)\n",
    "logo_path = \"D:/study/Projects/image.png\"  # Your local image path\n",
    "\n",
    "with gr.Blocks(title=\"Smart AI Chatbot\", css=\"\"\"\n",
    "    #main-col {\n",
    "        max-width: 600px;\n",
    "        margin: 0 auto !important;\n",
    "        padding-top: 20px;\n",
    "    }\n",
    "    .gr-button {\n",
    "        max-width: 200px;\n",
    "        margin: 0 auto;\n",
    "    }\n",
    "    .gr-textbox textarea {\n",
    "        font-size: 14px;\n",
    "    }\n",
    "    .center-image img {\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "    }\n",
    "\"\"\") as demo:\n",
    "\n",
    "    with gr.Column(elem_id=\"main-col\"):\n",
    "        gr.Image(value=logo_path, width=120, show_label=False, container=False, elem_classes=[\"center-image\"])\n",
    "\n",
    "        gr.Markdown(\"## ðŸ¤– Smart AI Chatbot\", elem_id=\"title\")\n",
    "        gr.Markdown(\"Ask anything â€” toggle between general knowledge and your own data!\", elem_id=\"subtitle\")\n",
    "\n",
    "        chatbot_ui = gr.Chatbot(label=\"ðŸ’¬ Chat History\")\n",
    "        input_box = gr.Textbox(label=\"ðŸ’¬ Your Question\", placeholder=\"Type your message here...\", lines=1)\n",
    "        use_personal = gr.Checkbox(label=\"ðŸ“š Use Personal Documents?\")\n",
    "        btn = gr.Button(\"ðŸš€ Submit\", size=\"sm\")\n",
    "        state = gr.State([])\n",
    "\n",
    "        def chat_handler(user_input, use_personal, chat_history):\n",
    "            if use_personal:\n",
    "                bot_reply = qa_pipeline.run(user_input)\n",
    "            else:\n",
    "                bot_reply = llm._call(user_input)\n",
    "\n",
    "            chat_history.append((user_input, bot_reply))\n",
    "            return chat_history, chat_history\n",
    "\n",
    "        btn.click(fn=chat_handler, inputs=[input_box, use_personal, state], outputs=[chatbot_ui, state])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d3447-d5b4-48db-bd3a-2bad11d09b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
